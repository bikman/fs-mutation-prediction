[general]
# select proteins train/eval set
# 1:ALL_PROTEINS_LIST
# 2:NORMAL_PROTEINS_LIST
# 3:COMPETITIVE_GROWTH_ASSAY_LIST
# 4:ANTIBIOTICS_RESISTANCE_LIST
# 5:DEBUG_LIST
protein_set = 1
#index of the protein file (1 to 39)
#to use for eval / fine tuning
eval_protein_file_number = 39
#step parameter for LR scheduler
step = 300
#the folder with all the pickled data
dump_root = /root/code/dumps
#default value 768
seq_emb_size = 768
#model:
#1: PrismScoreEmbDiffSimpleModel
#2: PrismScoreDeltasOnlyModel
#3: PrismScoreDeltasEmbDiffModel
#4: PrismScoreDeltasEmbModel
#5: PrismScoreNoDDGModel
#6: PrismScoreNoDDEModel
#7: PrismScoreNoDeltasModel
model = 1
#number of layers in transformer encoders
attn_len = 3
# length of embedding diff tensor (+-)
diff_len = 15
# number of channels in model
cz = 64

[flow_data_creation]
#index of protein to create data
#use -1 for 'all'
protein_id = -1
# 1 = normalize scores, 0 = do not normalize
normalize_scores = 0
# 1 = normalize deltas, 0 = do not normalize
normalize_deltas = 0

[fine_tuning_data_creation]
#how many items to take from list
# 1, 2, 4, 16, 32
data_count = 256
# 2 = normalize ds, 1 = normalize scores, 0 = do not normalize
normalize_scores = 0
# 1 = normalize deltas, 0 = do not normalize
normalize_deltas = 0
# add max orig score mutation to FT sample
add_max_v = 1

[flow_train]
batch_size = 48
heads = 8
epochs = 300
patience = 10000
#learning rate
lr = 0.0001
#loss parameter
alpha=1
#1=apply batch norm during train
batch_norm = 0

[flow_fine_tune]
#the folder with pickled previously trained model
fine_tune_folder = /root/code/model_fine_tune
#learning rate
lr = 0.0001
epochs = 30
loops = 10
#loss parameter
alpha=1
#1=apply batch norm during fine tuning
batch_norm = 0
# use min/max replacement in FT sample
use_min_max = 1

[flow_eval]
batch_size = 48
heads = 8






